# Implementation Plan: Chatbot UI Integration

**Feature Branch**: `main`
**Created**: 2025-12-23
**Status**: Draft
**Specification**: [specs/006-chatbot-ui-integration/spec.md](spec.md)

## 1. Technical Context

This plan outlines the steps to create a fully integrated chatbot UI within the Docusaurus frontend and connect it to the existing FastAPI backend.

-   **Frontend**: Docusaurus v3 / React.
    -   Key files to be created/modified:
        -   `frontend/src/components/ChatLauncher/index.tsx` (New)
        -   `frontend/src/components/ChatWindow/index.tsx` (New)
        -   `frontend/src/theme/Layout/index.tsx` (New - via Docusaurus swizzling)
        -   `frontend/src/css/custom.css` (Modification for chat styles)
-   **Backend**: FastAPI / Python.
    -   Key files to be modified:
        -   `backend/api.py`: Modify `/chat` endpoint to support streaming.
        -   `backend/agent.py`: Modify `GeminiRagAgent` to support streaming responses.
-   **Integration**: The frontend will communicate with the backend via HTTP requests to the `/chat` endpoint.

## 2. Constitution Check

-   [X] **SINGLE-BRANCH DEVELOPMENT ONLY**: All work will be performed on the `main` branch.
-   [X] **Top-Level Folder Structure**: All frontend changes are within `/frontend`, and all backend changes are within `/backend`.
-   [X] **File Responsibilities**: Modifications are confined to the appropriate files (`api.py`, `agent.py`, and new frontend components). No new backend files are created.
-   [X] **Free-Tier Services**: The implementation relies on existing free-tier services and does not introduce new costs.

The plan is compliant with all core principles of the project constitution.

## 3. Phase 0: Research

This phase addresses the key technical unknowns required to deliver the feature as specified, particularly the requirements for a global UI and a streaming response.

-   **R-01: Global Docusaurus Component:**
    -   **Task**: Research the best practice for implementing a persistent, site-wide UI component (the chatbot) in Docusaurus v3.
    -   **Hypothesis**: The recommended method is "swizzling" the root `Layout` component to wrap it with a new component that includes the chat launcher and window. This ensures the component is present on every page without modifying individual pages.
    -   **Outcome**: A clear technical decision on how to inject the chat UI globally.
-   **R-02: End-to-End Streaming Response:**
    -   **Task**: Investigate how to implement a streaming response from the backend agent to the frontend UI.
    -   **Area 1 (Backend API)**: How to change the `/chat` endpoint in `api.py` from a standard response to a `StreamingResponse` that can send `text/event-stream` data.
    -   **Area 2 (Backend Agent)**: How to modify the `GeminiRagAgent.chat()` method in `agent.py` to be an `async` generator that yields response chunks as they are generated by the Gemini model.
    -   **Area 3 (Agent Library)**: Critically, determine if the `openai-agents` library and its `Runner` class support asynchronous or streaming execution. If `Runner.run_sync` is the only option, it may be a **blocker** to achieving streaming without significant workarounds.
    -   **Area 4 (Frontend)**: How to use the `fetch` API or a similar library on the frontend to consume a `text/event-stream` response and update the UI progressively.
    -   **Outcome**: A clear, viable technical path for streaming responses, or a documented blocker if the agent library does not support it.

The output of this research will be documented in `research.md`.

## 4. Phase 1: Design & Contracts

### 4.1. Frontend Design

1.  **Chat Launcher Component (`frontend/src/components/ChatLauncher/index.tsx`):**
    -   A simple React component that renders a floating, robot-styled (ðŸ¤–) icon button.
    -   It will be fixed to the bottom-right of the viewport.
    -   On click, it will trigger a state change (likely via a shared React Context) to open the `ChatWindow`.
2.  **Chat Window Component (`frontend/src/components/ChatWindow/index.tsx`):**
    -   The main chat interface.
    -   Manages its own state for the list of messages, the current user input, and loading/error states.
    -   Renders the conversation history, including the initial greeting message.
    -   Contains a form with a text input and a submit button.
    -   On submit, it will:
        -   Add the user's message to the conversation history.
        -   Make a `fetch` call to the backend `/chat` endpoint.
        -   Handle the streaming response, progressively appending the agent's reply to the conversation history.
        -   Handle any API errors gracefully.
3.  **Global Layout Swizzling (`frontend/src/theme/Layout/index.tsx`):**
    -   Use the Docusaurus `swizzle` command to create a custom `Layout` component.
    -   This custom layout will import and render the `ChatLauncher` and `ChatWindow` components alongside the original page content.
    -   It will likely wrap the application in a `ChatContext.Provider` to manage the open/closed state of the chat window globally.
4.  **Styling (`frontend/src/css/custom.css`):**
    -   Add CSS rules to style the chat launcher and window to match the textbook's theme (colors, fonts, etc.).
    -   Ensure the components are responsive and do not interfere with the main content on mobile devices.

### 4.2. Backend Design

1.  **Streaming API Endpoint (`backend/api.py`):**
    -   Modify the `POST /chat` endpoint to be an `async def`.
    -   It will return a `fastapi.responses.StreamingResponse`.
    -   The endpoint will call an async generator function that wraps the agent's streaming logic.
2.  **Streaming Agent Logic (`backend/agent.py`):**
    -   Modify `GeminiRagAgent.chat()` to become an `async` method that returns an async generator.
    -   Inside this method, instead of `Runner.run_sync`, it will need to use an equivalent async/streaming call if available.
    -   If the agent library does not support streaming, a fallback to the current single-response mechanism will be used, and this deviation from the spec will be noted.

### 4.3. API Contracts (`contracts/chatbot-api.yml`)

An OpenAPI 3.0 snippet will be created to document the `/chat` endpoint.

```yaml
paths:
  /chat:
    post:
      summary: "Get a response from the RAG agent"
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                query:
                  type: string
                  description: "The user's question."
      responses:
        "200":
          description: "A streaming response of text chunks from the agent."
          content:
            text/event-stream:
              schema:
                type: string
```

### 4.4. Data Model (`data-model.md`)

The primary data entity is `ChatMessage`, which will be managed by the frontend.

-   **Entity**: `ChatMessage`
-   **Description**: Represents a single message within the chat conversation.
-   **Attributes**:
    -   `id`: `string` (A unique identifier, e.g., timestamp or UUID)
    -   `content`: `string` (The text of the message)
    -   `sender`: `'user' | 'assistant'` (Indicates who sent the message)

## 5. Quickstart (`quickstart.md`)

This document will provide instructions for running the integrated application:

1.  **Prerequisites**: Ensure all backend (`.env`) and frontend environment variables are configured.
2.  **Run Backend**:
    -   Navigate to `backend/`.
    -   Run `uv run uvicorn api:app --reload`.
3.  **Run Frontend**:
    -   Navigate to `frontend/`.
    -   Run `npm start`.
4.  **Testing**:
    -   Open the browser to the Docusaurus site (e.g., `http://localhost:3000`).
    -   Click the chat icon in the bottom-right corner.
    -   Ask a question like "What is ROS 2?" and verify that a streamed response appears.

This plan provides a comprehensive path to implementing the chatbot UI and integrating it end-to-end, with a critical research task to validate the streaming implementation.